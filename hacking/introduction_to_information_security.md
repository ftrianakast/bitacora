# First week: Introduction

0. Some important definitions:

a. Threat: Some possible actor/mecahnism that could harm your system
b. Vulnerability: Ways to exploite the system
c. Attack: Matterialization of exploding the vulnerability

1. Key security propertird (CIA):

a. Confidentiality:
b. Integrity
c. Availability

2. Security policy:

It is a state machine with authorized and unathorized nodes in which there is never a way to go from an authorized state to an unathorized state

3. Security Mechanism:

a. Prevention
b. Recovery
c. Detection

4. Trust

Trust is a tricky concept with many definitions, but in this course we will define trust as the expectation that arises within a community of regular, honest, cooperative behavior based on commonly shared norms

5. Some readings:

BlackHat / DefCon

# Second week: How to design security?

Have in mind some fundamental principles:

1. KISS
2. Open for extension
3. Less atonishment principle: Not allowing people to continue their work on their machine is unexpected, and violates the principle of least astonishment
4. Open design (a lot people can see and comment on your design)

Other principles:

1. Principle of minimizing secrets

2. Principle of complete mediation
Put more generally, all access to objects should be checked to ensure that the access is allowed. This is called the principle of complete mediation.

3. Principle of fail-safe defaults
Imagine that we are part of a website that stores, among other things, credit card data. When a new user joins the website, should they be granted access to that credit card data by default, or not? Though there are a few principles of secure design going on in this scenario, the most apparent one is the principle of fail-safe defaults. Our default value should be sane and secure. In this example, when a new user joins the service, the default should be that they should have no access to the credit card data held on the site. This default value should be assigned at the time of user creation, and should only be changed if absolutely needed (see the next principle). The idea here is to "fail-closed," meaning fail in a way that does not compromise the data and causes inconvenience, rather than "fail-open," where our method of failing allows the attacker to achieve some objective.

4. Principle of least privilige
This principle states that privileges should only be granted such that an individual can perform their duty, and nothing more. By extension, permissions must be granular enough to grant just the permissions needed to fulfill one's duty. If an elevation of privileges is necessary, it should last only as long as is needed and should be relinquished immediately after. Not only does this principle have large implications for security, it also ensures privacy by minimizing the amount of entities that may see data about or generated by users.

5. Principle of economy of mechanism

Smaller, simpler security mechanisms, however, lead to fewer errors, can be tested easier, and rely on less assumptions. Therefore, the principle of economy of mechanisms states that security mechanisms should be as simple as possible. For example, if we have a portion of a program that we are trusting to deal with sensitive data, or to properly perform a function, we should make sure that portion of trusted code is as small and simple as possible so it is easy to implement and verify.

6. Principle of least common mechanism
Last we have the principle of least common mechanism. This principle states that mechanisms used to access resources should not be shared. This is because shared resources can lead to denial-of-service attacks or other attacks. For example, an attacker can perform a denial-of-service attack on a website that you want to talk to because that website uses the same Internet connection to talk to you and to the attacker's machines. Some aspects of resource sharing can be mitigated through isolation techniques you will learn about later in this course.

## Ethics and law

Super important topic to also allways having it in mind when you do security stuff

## Cracking passwords

## How to protect passwords?


# Third week: Modeling Threats

Vulnerability of a system is some characteristic that makes it possible for a threat to occur.

Threat: to a system is any potential occurrence, malicious or otherwise, that can have an adverse effect on the assets and resources associated with the system.

Attack: on a system is some action that involves exploitation of some vulnerability in order to cause an existing threat to occur.

You need to determine your assets first and then the threats to this assets. You can model those threats with; Three Threats

## Main Steps of Threat Modeling

1. Understand your system
2. Understand what assets/resources need to be protected
3. Predict who the potential attackers are against a particular asset and what are the possible (known) attacks
4. Perform risk assessment. Determine what is the expected risk (quantitative or qualitative) because of an attack
5. Perform risk management: Employ security mechanisms (mitigation), if needed. Determine if they are cost effective

Now that we understand the steps of this process, how can we go through our system and systematically identify the threats to our system?

One way to do this is to use Microsoft's STRIDE Model, which categorizes threats into Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, and Elevation of Privilege.

We cannot stop at just knowing what's possible, however. We also need to rank these threats in order to know what is most important to take care of immediately. In order to do this we can use the DREAD ranking method, which allows us to rank threats based on Damage Potential, Reproducibility, Exploitation Cost, Affected Users, and Discoverability.

Attack trees allow us to systematically consider the potential attacks that may realize a threat. Though there is no guarantee that you will create a tree that represents all attacks, attack trees are still useful for sorting out thoughts on how attacks might occur, and can start to give us an understanding of how difficult an attack might be.

Before we can mitigate risk, we must first assess it. Risk analysis (or risk assessment) is the process of identifying assets at risk, putting measurements on potential loss, and assigning a probability of a negative event occurring. Said more mathematically:

risk=p(attack) x c(attack)

where p is a function that determines probability and c is a function that determines consequence.

a. Risk reduction
b. Risk mitigation
c. Risk transfer
d. Risk acceptance

## Risk Assessment

Risk assessment can be done in two major ways: quantitative or qualitative. Each of them have advantages and disadvantages, and can be suited towards different scenarios.

### Quantitative approach

In the quantitative approach to risk assessment, we compute expected monetary values that we expect to lose for all events that affect an asset. We can then calculate the probability that loss will happen. Using the formula provided earlier, we can see that this gives us an exact numerical risk that we can use when we move on to the risk management process.

### Qualitative approach:

In the qualitative approach to risk management, we can use categories such as low, medium, high or other labels to stand in for numerical values. We can then use these to calculate a risk. For example, we can say that an event that has a high impact but a low probability has a medium risk. A more interesting example could be a medium probability but a high impact, giving us a medium-high risk.

The levels of classified information from the Department of Defense is a good example of how risk can be qualitatively labeled. The Department of Defense labels data as confidential, secret, or top secret based on the guidelines below.

Confidential: “shall be applied to information, the unauthorized disclosure of which reasonably could be expected to cause damage to the national security”
Secret: “shall be applied to information, the unauthorized disclosure of which reasonably could be expected to cause serious damage to the national security”
Top Secret: “shall be applied to information, the unauthorized disclosure of which reasonably could be expected to cause exceptionally grave damage to the national security”

Classification of threats

a. Spoofing- Using someone else’s credentials to gain access to otherwise inaccessible assets.
b. Tampering- Changing data to mount an attack.
c. Repudiation- Occurs when a user denies performing an
action, but the target of the action has no way to prove
otherwise.
d. Information disclosure- The disclosure of information
to a user who does not have permission to see it.
e. Denial of service- Reducing the ability of valid users
to access resources.
f. Elevation of privilege- Occurs when an unprivileged
user gains privileged status


Risk management consists of risk assessment, risk reduction, and risk acceptance.
To assess the risk of identified threats, the threats must be
prioritized. The simplest way to prioritize threats is by using two factors: damage and likelihood.

There are 4 wazs to manage an specific risk:


a) Accept the risk - The risk is so low and so costly to mitigate that it is worth accepting.
b) Transfer the risk - Transfer the risk to somebody else via
insurance, warnings etc.
c) Remove the risk - Remove the system component or feature associated with the risk if the feature is not worth the risk.
d) Mitigate the risk - Reduce the risk with countermeasures

### Quantitative approach

Exact cost = probability of happening + cost of happening

- Pros of quantitative analysis

a. Very good Rekialibility questions

- Cons

a. Not easy to calculate. Very low condifence value thatcomes from the analysis


 The phrase “kill chain”
describes the structure of the intrusion, and the corresponding model guides analysis to inform actionable
security intelligence.

Computer risk assesment: https://medium.com/@secse/computing-risk-assessment-5d5814a118ff

A kill chain is a systematic process to target and engage an adversary to create desired effects. U.S. military targeting doctrine defines the steps of this process as find, fix, track, target, engage, assess
(F2T2EA): find adversary targets suitable for engagement; fix their location; track and observe; target with suitable weapon or asset to create desired effects; engage adversary; assess effects (U.S. Department of Defense, 2007). This is an integrated, end-to-end process described as a “chain” because any one deficiency will interrupt the entire process.

# Forth Week: Security Policies

Different organizations have different assets they control, threats they face, and goals they wish to achieve. Therefore, different organizations will have to create different security policies to follow in order to keep their organization secure.

Typically security policies come in two forms. The first form is a security policy that lists a series of rules that must be followed in order to ensure the safety of the organization. In other words, the policy tells you what you are not supposed to be able to do. An example of this is NYU's security policy, which you should read and become familiar with. Though these policies are useful and adaptive, they are less technical and less complete. Imprecise wording can lead individuals in the organization to make mistakes, and oversights during policy development can lead to glaring holes in security that attackers can take advantage of.

However, there is a more technical and complete way to model a security policy. If we consider a computer system to be a finite state automaton with state transitions then the following holds true.

A security policy is a statement that partitions the states of a system into a set of authorized or secure states and a set of unauthorized or non-secure states.

A secure system is a system that starts in an authorized state and cannot enter an unauthorized state.

A breach of security occurs when a system enters an unauthorized state.

As in previous lessons, the following video provides more context to the concept of a security policy, and allows you to more fully compare and contrast the two types.
For each asset an organization controls, we can create policies relating to the confidentiality, integrity, and availability of that asset. Below we provide more rigorous definitions that we have previously.  In each of the definitions we have some entities (that we call X) that want access to information (that we call Y).

__Confidentiality__: Let X be a set of entities and Y  be some information. Then Y has the property of confidentiality with respect to X if no member of X can obtain information about Y .

__Integrity__: Let X be a set of entities and Y  some information. Then Y has the property of integrity with respect to X if Y  is unmodifiable by X.

__Availability__: Let X be a set of entities and Y  a resource. Then Y has the property of availability with respect to X if all members of X can access Y .

In the following video we will explore how policies can address combinations of confidentiality, integrity, and availability in order to achieve some higher goal of the system. In addition, we will reintroduce the difference between a mechanism and a policy, and provide an example for you to think about.

## Security Policy Model: Bell-La Padula (Confidentiality)

__Simple Security Property__: L(o) <= L(s)

A subject s may have read access to an object o if and only if L(o) <= L(s) and s has discretionary read access to o.
(Security clearance of subject has to be at least as high as that of the object).

__*-Property__ (start property): L(o) >= L(p)
A subject s who has read access to an object p may have write access to an object o only if L(o) >= L(p) and s has discretionary write access to o.
(Contents of a sensitive object can only be written to objects at least as high. That is, prevent write-down).

__Tranquility Principle__: How often the permissions change in a asystem.

If you have the simple security property and the start  property then you have a secure system

## Biba Integrity Model (Integrity of the model)

Our next model, the Biba Integrity model, is related to the Bell-Lapadula model in that is has a very similar strict hierarchical construction. However, the Biba model focuses on integrity instead of confidentiality, and therefore inverts the rules of the labeling. Each piece of data is labeled with an integrity label, as is each entity in the system. If a given entity wants to write to a piece of data, the data should benefit from the integrity of the individual, or at least remain neutral. For this reason the entity can only write equal to its level, or write down. However, entities should only read material that would increase their integrity. For that reason, the entity should only be able to read documents that are labeled with an integrity label greater than or equal to their own.


The Biba model tries to avoid integrity violations, so one does not want to write into a source with higher integrity than them (since that would violate the integrity of the source) or read a source with less integrity than them (since that would violate their integrity).
## Lipner's Model

Lipner's model is a much more practical model than the previous two we discussed, and something more like Lipner's model is more likely to be found in a real organization. This model contains three principles that are used to ensure that the organization remains safe. There principles are separation of duty, separation of function, and auditing. If an organization follows separation of duty, if two or more steps are required to perform a critical function, at least two different people should perform the steps. If an organization follows the separation of function, then resources such as servers, repositories, etc., should be isolated from each other based on function. A development server should hold code in development, while a production server should host the code for people to access. Finally, an organization should audit, that is they should analyze systems to determine what actions took place, and who performed them. In the following video we will explore this in more detail, and discuss how this breaks down into a combination of the two previous policy models in different compartments.

## Clark Wilson Integrity Model

In the Biba model and the Lipner model we have considered who can change what information, but we never put any thought into how an entity is allowed to change data. This idea is tackled by the Clark-Wilson Integrity model.

The Clark-Wilson model is primarily concerned with formalizing the notion of information integrity. Information integrity is maintained by preventing corruption of data items in a system due to either error or malicious intent. An integrity policy describes how the data items in the system should be kept valid from one state of the system to the next and specifies the capabilities of various principles in the system. The model defines enforcement rules and certification rules. The model’s enforcement and certification rules define data items and processes that provide the basis for an integrity policy.

In the following video we will explore the Clark-Wilson model on a high level, and discuss how banks use it to ensure that transactions are properly recorded and no money is lost in the records.

__Transaction__: There is party that makes the transaction and another one that verify that the transaction does not pollute

## Chinese Wall Model

Consider a consulting agency that provides some form of business assistance to multiple companies. If this consulting agency is meant to provide its services for multiple competing companies, this could lead to conflicts of interest. However, if the consulting agency only works for companies that do not directly compete with each other, conflicts of interest are avoided. This is the general principle of the Chinese Wall model. In the following video we will explore the Chinese wall model, and describe how it helps us avoid issues with leaking information to competing systems.

## Trust

Trust is a tricky concept with many definitions, but in this course we will define trust as the expectation that arises within a community of regular, honest, cooperative behavior based on commonly shared norms1. So when we say we trust a mechanism, we are not actually trusting that mechanism. Instead, we are trusting the organization that created that mechanism, and we are trusting them because of a common set of norms that we share with them.

Whenever we are applying a mechanism to protect a part of our system, we are creating a trust boundary. If we think of our system as a plane, we are dividing the plane into two areas, one where we expect there are parties we distrust, and one that we suspect is only accessible to parties we trust. The mechanism is meant to mitigate access to ensure that this remains true.

In this section of the lesson we will discuss how trust and security policies interact, and provide trust considerations that are made when writing security policies and when choosing security mechanisms.


## Designing Policies

Should policies have to explicitly allow things in order for them to happen (called inclusive policies), or should they only prohibit certain, explicitly stated behaviors and allow everything else (called exclusive policies)?


Security policies are used in many different areas of an organization. Policies can include rules on technical things such as password generation, storage and rotation, and how cryptographic keys are handled. They can also handle less technical things such as the organization's policy on how to handle web browsing that isn't work-related. In the following video we will explore several areas in which policies may apply.


It is a good idea to review sample policies to become familiar with what they cover, and how they typically work in practice. Two places provide good policies or policy related information to jump-start your search. They are SANS and NIST.

The SANS (SysAdmin, Audit, Network, Security) Institute has sample security policies available on-line in many areas. These can be downloaded and used as is, or modified to the needs of a specific company.

The NIST (National Institute of Standards and Technology) site lots of material on security including technology, best practices, policies, regulations, and others. Use the term “security policy” in the search bar.